facebook removes 8.7 million sexual photos of kids in last three months
san
francisco
reuters
facebook
inc
said
on
wednesday
that
company
moderators
during
the
last
quarter
removed
million
user
images
of
child
nudity
with
the
help
of
previously
undisclosed
software
that
automatically
flags
such
photos
the
machine
learning
tool
rolled
out
over
the
last
year
identifies
images
that
contain
both
nudity
and
a
child
allowing
increased
enforcement
of
facebook
s
ban
on
photos
that
show
minors
in
a
sexualized
context
a
similar
system
also
disclosed
on
wednesday
catches
users
engaged
in
grooming
or
befriending
minors
for
sexual
exploitation
facebook
s
global
head
of
safety
antigone
davis
told
reuters
in
an
interview
that
the
machine
helps
us
prioritize
and
more
efficiently
queue
problematic
content
for
the
company
s
trained
team
of
reviewers
the
company
is
exploring
applying
the
same
technology
to
its
instagram
app
under
pressure
from
regulators
and
lawmakers
facebook
has
vowed
to
speed
up
removal
of
extremist
and
illicit
material
machine
learning
programs
that
sift
through
the
billions
of
pieces
of
content
users
post
each
day
are
essential
to
its
plan
machine
learning
is
imperfect
and
news
agencies
and
advertisers
are
among
those
that
have
complained
this
year
about
facebook
s
automated
systems
wrongly
blocking
their
posts
davis
said
the
child
safety
systems
would
make
mistakes
but
users
could
appeal
we
d
rather
err
on
the
side
of
caution
with
children
she
said
facebook
s
rules
for
years
have
banned
even
family
photos
of
lightly
clothed
children
uploaded
with
good
intentions
concerned
about
how
others
might
abuse
such
images
before
the
new
software
facebook
relied
on
users
or
its
adult
nudity
filters
to
catch
child
images
a
separate
system
blocks
child
pornography
that
has
previously
been
reported
to
authorities
facebook
has
not
previously
disclosed
data
on
child
nudity
removals
though
some
would
have
been
counted
among
the
million
posts
and
comments
it
removed
in
the
first
quarter
for
sexual
activity
and
adult
nudity
shares
of
facebook
fell
percent
on
wednesday
facebook
said
the
program
which
learned
from
its
collection
of
nude
adult
photos
and
clothed
children
photos
has
led
to
more
removals
it
makes
exceptions
for
art
and
history
such
as
the
pulitzer
photo
of
a
naked
girl
fleeing
a
vietnam
war
napalm
attack
the
child
grooming
system
evaluates
factors
such
as
how
many
people
have
blocked
a
particular
user
and
whether
that
user
quickly
attempts
to
contact
many
children
davis
said
michelle
delaune
chief
operating
officer
at
the
national
center
for
missing
and
exploited
children
ncmec
said
the
organization
expects
to
receive
about
million
child
porn
tips
worldwide
this
year
from
facebook
and
other
tech
companies
up
from
million
last
year
with
the
increase
ncmec
said
it
is
working
with
facebook
to
develop
software
to
decide
which
tips
to
assess
first
still
delaune
acknowledged
that
a
crucial
blind
spot
is
encrypted
chat
apps
and
secretive
dark
web
sites
where
much
of
new
child
pornography
originates
encryption
of
messages
on
whatsapp
for
example
prevents
machine
learning
from
analyzing
them
delaune
said
ncmec
would
educate
tech
companies
and
hope
they
use
creativity
to
address
the
issue
reporting
by
paresh
dave
editing
by
greg
mitchell
