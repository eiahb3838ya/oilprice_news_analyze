{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from math import *\n",
    "from datetime import datetime\n",
    "from progressbar import progressbar\n",
    "\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "from gensim.summarization.summarizer import summarize\n",
    "from gensim.summarization import keywords\n",
    "from gensim.summarization.textcleaner import get_sentences\n",
    "from gensim.summarization.textcleaner import clean_text_by_sentences\n",
    "from gensim.models.doc2vec import Doc2Vec,TaggedDocument\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-12 2018-07 2018-08 2018-10\n"
     ]
    }
   ],
   "source": [
    "TRAIN_START_DATE = \"2017-12\"\n",
    "\n",
    "TRAIN_INTIVAL = 7\n",
    "TEST_INTIVAL = 2\n",
    "\n",
    "\n",
    "from_date = TRAIN_START_DATE\n",
    "to_date = str(np.datetime64(TRAIN_START_DATE) +\n",
    "              np.timedelta64(TRAIN_INTIVAL, 'M'))\n",
    "test_from_date = str(np.datetime64(to_date) +\n",
    "              np.timedelta64(1, 'M'))\n",
    "test_to_date = str(np.datetime64(test_from_date)+np.timedelta64(TEST_INTIVAL, 'M'))\n",
    "\n",
    "print(from_date,to_date,test_from_date,test_to_date)\n",
    "window_size=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_documents,vector_size=300):\n",
    "    model = Doc2Vec(train_documents, vector_size=vector_size, window=4, min_count=2, workers=12)\n",
    "    model.train(train_documents,total_examples=model.corpus_count,epochs=30)\n",
    "    return(model)\n",
    "def get_content(data_df):\n",
    "    content=data_df.content\n",
    "    content.index = pd.DatetimeIndex(content.index)\n",
    "    content=content.dropna(how=\"any\")\n",
    "    return(content)\n",
    "class Preprocessor:\n",
    "    def __init__(self,stopword=[],use_stem=False,use_summarize=True,summarize_word_count=200):\n",
    "        self.use_stem=use_stem\n",
    "        self.use_summarize=use_summarize\n",
    "        self.summarize_word_count=summarize_word_count\n",
    "        self.stopword=stopword\n",
    "    def stem_and_other_stuff(self,each_news):\n",
    "        ps=PorterStemmer()\n",
    "        return([ps.stem(word.lower()) for word in each_news.split(\" \") if word.isalpha() and word not in self.stopword])\n",
    "    \n",
    "    def check_alpha_tolower(self,each_news):\n",
    "        return([word.lower() for word in each_news.split(\" \") if word.isalpha()])\n",
    "        \n",
    "    def get_tokenized_content(self,content):\n",
    "        tokenized_content_s=content.apply(word_tokenize)\n",
    "        if self.use_stem:        \n",
    "            output_token=tokenized_content_s.apply(self.stem_and_other_stuff)\n",
    "        else:\n",
    "            output_token=tokenized_content_s.apply(self.check_alpha_tolower)\n",
    "        return(output_token)\n",
    "    \n",
    "    def get_counter(self,content):\n",
    "        tokenized_content_s=self.get_tokenized_content(content)\n",
    "        content_counter=Counter()\n",
    "        for aStemmed_token in tokenized_content_s:\n",
    "            content_counter.update(aStemmed_token)\n",
    "#             self.counter = content_counter\n",
    "        return(content_counter)\n",
    "    \n",
    "    def get_summarize(self,content,summarize_ratio=None):\n",
    "        if summarize_ratio:\n",
    "            return(content.apply(lambda txt:summarize(txt,word_count = summarize_word_count)))\n",
    "        else:\n",
    "            return(content.apply(lambda txt:summarize(txt,word_count = self.summarize_word_count)))\n",
    "#             return(content.apply(lambda txt:summarize(txt,ratio = self.summarize_ratio)))\n",
    "    def preprocess(self,content):\n",
    "        if self.use_summarize:\n",
    "            content=content.loc[content.apply(clean_text_by_sentences).apply(list).apply(len).apply(lambda x:x>1)]\n",
    "            content=self.get_summarize(content)\n",
    "        content_counter=self.get_counter(content)\n",
    "        return(content_counter)\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "class MyStopWord:\n",
    "    def __init__(self,content_counter,most_common=100,stop_word=None):\n",
    "        from nltk.corpus import stopwords\n",
    "        self.counter_stop_word=[word for word,time in content_counter.most_common(most_common)]\n",
    "        self.user_keep=[]\n",
    "        self.user_define=[]\n",
    "        if stop_word:\n",
    "            self.stop_word=stop_word\n",
    "        else:\n",
    "            self.stop_word=set(self.counter_stop_word+stopwords.words('english')) \n",
    "    def keep(self,word):\n",
    "        self.user_keep.append(word)\n",
    "        self.stop_word.discard(word)\n",
    "    def define(self,word):\n",
    "        self.user_define.append(word)\n",
    "        self.stop_word.add(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../../data/crawler_news_data/oilprice_news.csv\")\n",
    "raw_df_cnbc = pd.read_csv(\"../../data/crawler_news_data/cnbc_oil_news.csv\")\n",
    "bdate=pd.bdate_range(\"2009\",\"2019\")\n",
    "\n",
    "raw_df.publish_datetime=pd.DatetimeIndex(raw_df.publish_datetime)\n",
    "raw_df.loc[~raw_df.publish_datetime.isin(bdate),'publish_datetime']=np.nan\n",
    "raw_df.publish_datetime=raw_df.publish_datetime.fillna(method='ffill')\n",
    "\n",
    "raw_df_cnbc.story_publish_datetime=pd.DatetimeIndex(raw_df_cnbc.story_publish_datetime)\n",
    "raw_df_cnbc.loc[~raw_df_cnbc.story_publish_datetime.isin(bdate),'story_publish_datetime']=np.nan\n",
    "raw_df_cnbc.story_publish_datetime=raw_df_cnbc.story_publish_datetime.fillna(method='ffill')\n",
    "\n",
    "data_df=raw_df.sort_values(by=\"publish_datetime\",ascending=True).set_index('publish_datetime')\n",
    "data_df_cnbc = raw_df_cnbc.sort_values(by=\"story_publish_datetime\",ascending=True).set_index('story_publish_datetime')\n",
    "data_df_oilprice = pd.DataFrame({\"date\":raw_df.publish_datetime,\"content\":raw_df.content})\n",
    "data_df_cnbc = pd.DataFrame({\"date\":raw_df_cnbc.story_publish_datetime,\"content\":raw_df_cnbc.story_full_article})\n",
    "data_df_oilprice_cnbc = data_df_oilprice.append(data_df_cnbc)\n",
    "data_df_oilprice_cnbc = data_df_oilprice_cnbc.sort_values(by=\"date\",ascending=True).set_index('date')\n",
    "raw_content = get_content(data_df_oilprice_cnbc)\n",
    "raw_content=raw_content.loc[raw_content.apply(clean_text_by_sentences).apply(list).apply(len).apply(lambda x:x>1)]\n",
    "raw_train_content=raw_content[from_date:to_date]\n",
    "raw_test_content=raw_content[test_from_date:test_to_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>latest</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>quantity</th>\n",
       "      <th>percentage</th>\n",
       "      <th>two_day_percentage</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-10-28</th>\n",
       "      <td>1331</td>\n",
       "      <td>98.68</td>\n",
       "      <td>97.88</td>\n",
       "      <td>98.82</td>\n",
       "      <td>97.37</td>\n",
       "      <td>230.16K</td>\n",
       "      <td>0.85</td>\n",
       "      <td>-0.019355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-10-30</th>\n",
       "      <td>1329</td>\n",
       "      <td>96.77</td>\n",
       "      <td>97.77</td>\n",
       "      <td>97.82</td>\n",
       "      <td>96.55</td>\n",
       "      <td>268.14K</td>\n",
       "      <td>-1.46</td>\n",
       "      <td>-0.022321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-08</th>\n",
       "      <td>1322</td>\n",
       "      <td>94.60</td>\n",
       "      <td>94.36</td>\n",
       "      <td>94.92</td>\n",
       "      <td>93.90</td>\n",
       "      <td>241.69K</td>\n",
       "      <td>0.42</td>\n",
       "      <td>-0.016490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-11</th>\n",
       "      <td>1321</td>\n",
       "      <td>95.14</td>\n",
       "      <td>94.45</td>\n",
       "      <td>95.38</td>\n",
       "      <td>94.11</td>\n",
       "      <td>206.72K</td>\n",
       "      <td>0.57</td>\n",
       "      <td>-0.013244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-11-19</th>\n",
       "      <td>1315</td>\n",
       "      <td>93.34</td>\n",
       "      <td>93.00</td>\n",
       "      <td>93.46</td>\n",
       "      <td>92.43</td>\n",
       "      <td>131.46K</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.022498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0  latest   open   high    low quantity  percentage  \\\n",
       "date                                                                       \n",
       "2013-10-28        1331   98.68  97.88  98.82  97.37  230.16K        0.85   \n",
       "2013-10-30        1329   96.77  97.77  97.82  96.55  268.14K       -1.46   \n",
       "2013-11-08        1322   94.60  94.36  94.92  93.90  241.69K        0.42   \n",
       "2013-11-11        1321   95.14  94.45  95.38  94.11  206.72K        0.57   \n",
       "2013-11-19        1315   93.34  93.00  93.46  92.43  131.46K        0.33   \n",
       "\n",
       "            two_day_percentage  \n",
       "date                            \n",
       "2013-10-28           -0.019355  \n",
       "2013-10-30           -0.022321  \n",
       "2013-11-08           -0.016490  \n",
       "2013-11-11           -0.013244  \n",
       "2013-11-19            0.022498  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effective_news_df = pd.read_csv(\"../../data/crude_oil_price/effective_news_date_days_before_and_after.csv\")\n",
    "effective_news_df.date=pd.DatetimeIndex(effective_news_df.date)\n",
    "effective_news_df=effective_news_df.set_index('date')\n",
    "effective_news_date = effective_news_df.index\n",
    "effective_news_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocesser=Preprocessor()\n",
    "all_year_counter = preprocesser.preprocess(content=raw_content)\n",
    "mystopword=MyStopWord(content_counter=all_year_counter,most_common=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_word_list=preprocesser.get_tokenized_content(raw_content)\n",
    "train_word_list=doc_word_list[from_date:to_date]\n",
    "test_word_list=doc_word_list[test_from_date:test_to_date]\n",
    "train_documents=[TaggedDocument(doc, [i]) for i, doc in enumerate(train_word_list)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=train(train_documents=train_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1644"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vs_df=pd.DataFrame(model.docvecs.vectors_docs).set_index(train_word_list.index)\n",
    "train_vs_df['tags'] = 0\n",
    "train_vs_df.loc[train_vs_df.index.isin(effective_news_date),'tags']=1\n",
    "train_vs_df.to_csv(\"../../data/train_test_dataset/oilprice_cnbc_new_train.csv\")\n",
    "\n",
    "len(train_vs_df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "893"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs_np=np.array([model.infer_vector(doc_words=word_list,alpha=0.01,steps=500) for word_list in test_word_list])\n",
    "test_vs_df=pd.DataFrame(test_vs_np).set_index(test_word_list.index)\n",
    "test_vs_df['tags'] = 0\n",
    "test_vs_df.loc[test_vs_df.index.isin(effective_news_date),'tags']=1\n",
    "test_vs_df.to_csv(\"../../data/train_test_dataset/oilprice_cnbc_new_test.csv\")\n",
    "\n",
    "len(test_vs_df['tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(893, 301)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_vs_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
