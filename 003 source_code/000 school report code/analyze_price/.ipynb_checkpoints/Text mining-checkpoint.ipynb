{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk,re\n",
    "import pandas as pd\n",
    "from nltk import sent_tokenize,word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from pprint import pprint\n",
    "from collections import Counter\n",
    "from math import *\n",
    "from datetime import datetime\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 118 entries, 0 to 117\n",
      "Data columns (total 10 columns):\n",
      "Unnamed: 0          118 non-null int64\n",
      "Unnamed: 0.1        118 non-null int64\n",
      "index               118 non-null int64\n",
      "datetime            118 non-null object\n",
      "publish_time_str    118 non-null object\n",
      "source              118 non-null object\n",
      "Abstract            118 non-null object\n",
      "Content             118 non-null object\n",
      "Title               118 non-null object\n",
      "tags                118 non-null int64\n",
      "dtypes: int64(4), object(6)\n",
      "memory usage: 9.3+ KB\n",
      "None\n",
      "datetime\n",
      "2018-09-19    HOUSTON, Sept. 19, 2018 /PRNewswire/ -- Global...\n",
      "2018-09-20    The \"Oil Field Chemicals Market: Global Indust...\n",
      "2018-09-20    The \"Natural Gas Refueling Infrastructure: Glo...\n",
      "2018-09-20     Consulting, engineering and construction serv...\n",
      "2018-09-20    CLEVELAND, Sept. 20, 2018 /PRNewswire/ -- US m...\n",
      "Name: Content, dtype: object\n"
     ]
    }
   ],
   "source": [
    "path = \"../../data/ebscohost_history_data/crude_oil_news_data.csv\"\n",
    "raw_df=pd.read_csv(path)\n",
    "print(raw_df.info())\n",
    "data_df=raw_df.set_index('datetime').drop(columns='Unnamed: 0',axis=1)\n",
    "content=data_df.Content\n",
    "print(content.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_and_other_stuff(each_news):\n",
    "    ps=PorterStemmer()\n",
    "    return([ps.stem(word.lower()) for word in each_news if word.isalpha()])\n",
    "def check_alpha_tolower(each_news)\n",
    "    return([word.lower() for word in each_news if word.isalpha()])\n",
    "\n",
    "def to_counter(this_year_content,stem=True):\n",
    "    token_content=pd.Series()\n",
    "    token_content=this_year_content.apply(word_tokenize)\n",
    "    ps=PorterStemmer()\n",
    "    if stem:        \n",
    "        stemmed_content=token_content.apply(stem_and_other_stuff)\n",
    "    else:\n",
    "        stemmed_content=token_content.apply(check_alpha_tolower)\n",
    "    content_counter = Counter()\n",
    "    for news in stemmed_content:\n",
    "        content_counter.update(news)\n",
    "    return(stemmed_content,content_counter)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# stemming and get target news date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_year_content=content[\"2017-11\":]\n",
    "this_year_token, this_year_counter = to_counter(this_year_content)\n",
    "\n",
    "effective_news_df=pd.read_csv(\"effective_news_date.csv\")\n",
    "effective_news_date = effective_news_df['date']\n",
    "effective_news_date=pd.DatetimeIndex(effective_news_date)\n",
    "\n",
    "content.index = pd.DatetimeIndex(content.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get token and target token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eiahb\\AppData\\Local\\conda\\conda\\envs\\env_futures\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: \n",
      "Passing list-likes to .loc or [] with any missing label will raise\n",
      "KeyError in the future, you can use .reindex() as an alternative.\n",
      "\n",
      "See the documentation here:\n",
      "https://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate-loc-reindex-listlike\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "target_content = content.loc[effective_news_date.values].dropna(how=\"any\")\n",
    "other_content=content.loc[~this_year_content.index.isin(effective_news_date.values)].dropna(how=\"any\")\n",
    "target_token, target_counter = to_counter(target_content)\n",
    "other_token, other_counter = to_counter(other_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime\n",
       "2018-09-27    [as, previous, disclos, on, juli, ngl, energi,...\n",
       "2018-09-27    [phillip, partner, nyse, psxp, announc, today,...\n",
       "2018-09-28    [global, adsorb, market, research, inform, by,...\n",
       "2018-09-28    [houston, pin, oak, corpu, christi, llc, pin, ...\n",
       "2018-09-28    [global, soda, ash, market, by, applic, glass,...\n",
       "2018-10-03    [appl, reach, a, new, high, with, a, advanc, a...\n",
       "2018-10-03    [the, global, build, thermal, insul, market, b...\n",
       "2018-10-03    [technavio, analyst, forecast, the, biolubric,...\n",
       "2018-10-03    [rt, moex, russia, gain, at, open, rosseti, ra...\n",
       "2018-10-03    [rt, moex, russia, gain, at, open, rosseti, ra...\n",
       "2018-10-03    [new, york, the, distil, system, market, is, p...\n",
       "2018-10-03    [rt, moex, russia, gain, at, open, rosseti, ra...\n",
       "2018-10-03    [salt, creek, midstream, llc, creek, a, portfo...\n",
       "2018-10-09    [with, pipelin, plan, falter, memori, turn, to...\n",
       "2018-10-10    [the, saudi, arabia, structur, cabl, market, m...\n",
       "2018-10-15    [the, emerg, opportun, for, materi, deriv, fro...\n",
       "2018-10-15    [tallgrass, energi, lp, nyse, tge, and, silver...\n",
       "2018-10-15    [new, york, oil, and, ga, compani, with, integ...\n",
       "2018-10-15    [new, york, report, scopeth, market, for, indu...\n",
       "2018-10-15    [canadian, produc, deal, with, discount, far, ...\n",
       "2018-10-16    [stock, bolt, higher, tuesday, as, the, dow, s...\n",
       "2018-10-16    [kashagan, produc, mln, tonn, of, oil, in, oct...\n",
       "2018-10-16    [oil, demand, be, hit, the, chief, execut, of,...\n",
       "2018-10-16    [new, york, thi, report, analyz, the, worldwid...\n",
       "2018-10-16    [kazakhstan, kashagan, produc, mln, tonn, of, ...\n",
       "2018-10-19    [energi, transfer, lp, nyse, et, today, announ...\n",
       "2018-10-19    [econom, growth, and, interest, rate, appear, ...\n",
       "2018-10-19    [schlumberg, slb, said, strong, oil, demand, w...\n",
       "2018-10-19    [oil, fell, below, a, barrel, as, a, rise, in,...\n",
       "2018-10-22    [intercontinent, exchang, nyse, ice, a, lead, ...\n",
       "2018-10-22    [global, toluen, market, by, grade, commerci, ...\n",
       "Name: Content, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_set=set(other_counter.keys())\n",
    "target_corpus_set=set(target_counter.keys())\n",
    "stop_word = list(set(dict(target_counter.most_common(50)).keys()) | set(dict(this_year_counter.most_common(50)).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word=[word for word,time in this_year_counter.most_common(60)]\n",
    "keep = ['energi','increas','growth']\n",
    "stop_word = [ word for word in stop_word if word not in keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of\tthe\t122\n",
      "in\tthe\t107\n",
      "crude\toil\t78\n",
      "the\tmarket\t39\n",
      "oil\tand\t36\n",
      "with\tthe\t31\n",
      "and\tthe\t30\n",
      "or\temail\t30\n",
      "for\tthe\t29\n",
      "the\tcompani\t29\n",
      "expect\tto\t28\n",
      "demand\tfor\t27\n",
      "to\tthe\t27\n",
      "on\tthe\t27\n",
      "is\tthe\t27\n",
      "and\tga\t26\n",
      "dure\tthe\t25\n",
      "to\tbe\t25\n",
      "to\ta\t25\n",
      "by\tthe\t24\n"
     ]
    }
   ],
   "source": [
    "word_pair_counts = Counter()\n",
    "tokens = target_content\n",
    "\n",
    "for tokens in target_token:\n",
    "    for i in range(len(tokens) - 1):\n",
    "        (w1, w2) = (tokens[i], tokens[i + 1])\n",
    "        word_pair_counts[(w1, w2)] += 1\n",
    "    \n",
    "for pair, c in word_pair_counts.most_common(20):\n",
    "    print(\"%s\\t%s\\t%d\" % (pair[0], pair[1], c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\eiahb\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(('content', 'copi', 4), 53),\n",
       " (('content', 'multipl', 8), 53),\n",
       " (('copi', 'multipl', 4), 53),\n",
       " (('copi', 'site', 5), 53),\n",
       " (('copi', 'post', 7), 53),\n",
       " (('multipl', 'site', 1), 53),\n",
       " (('multipl', 'post', 3), 53),\n",
       " (('multipl', 'listserv', 6), 53),\n",
       " (('multipl', 'without', 7), 53),\n",
       " (('site', 'post', 2), 53),\n",
       " (('site', 'listserv', 5), 53),\n",
       " (('site', 'without', 6), 53),\n",
       " (('post', 'listserv', 3), 53),\n",
       " (('post', 'without', 4), 53),\n",
       " (('post', 'holder', 7), 53),\n",
       " (('post', 'express', 8), 53),\n",
       " (('listserv', 'without', 1), 53),\n",
       " (('listserv', 'holder', 4), 53),\n",
       " (('listserv', 'express', 5), 53),\n",
       " (('listserv', 'written', 6), 53),\n",
       " (('listserv', 'permiss', 7), 53),\n",
       " (('listserv', 'howev', 8), 53),\n",
       " (('without', 'holder', 3), 53),\n",
       " (('without', 'express', 4), 53),\n",
       " (('without', 'written', 5), 53),\n",
       " (('without', 'permiss', 6), 53),\n",
       " (('without', 'howev', 7), 53),\n",
       " (('without', 'user', 8), 53),\n",
       " (('holder', 'express', 1), 53),\n",
       " (('holder', 'written', 2), 53),\n",
       " (('holder', 'permiss', 3), 53),\n",
       " (('holder', 'howev', 4), 53),\n",
       " (('holder', 'user', 5), 53),\n",
       " (('holder', 'print', 7), 53),\n",
       " (('holder', 'download', 8), 53),\n",
       " (('express', 'written', 1), 53),\n",
       " (('express', 'permiss', 2), 53),\n",
       " (('express', 'howev', 3), 53),\n",
       " (('express', 'user', 4), 53),\n",
       " (('express', 'print', 6), 53),\n",
       " (('express', 'download', 7), 53),\n",
       " (('written', 'permiss', 1), 53),\n",
       " (('written', 'howev', 2), 53),\n",
       " (('written', 'user', 3), 53),\n",
       " (('written', 'print', 5), 53),\n",
       " (('written', 'download', 6), 53),\n",
       " (('permiss', 'howev', 1), 53),\n",
       " (('permiss', 'user', 2), 53),\n",
       " (('permiss', 'print', 4), 53),\n",
       " (('permiss', 'download', 5), 53),\n",
       " (('permiss', 'articl', 8), 53),\n",
       " (('howev', 'user', 1), 53),\n",
       " (('howev', 'print', 3), 53),\n",
       " (('howev', 'download', 4), 53),\n",
       " (('howev', 'articl', 7), 53),\n",
       " (('user', 'print', 2), 53),\n",
       " (('user', 'download', 3), 53),\n",
       " (('user', 'articl', 6), 53),\n",
       " (('user', 'individu', 8), 53),\n",
       " (('print', 'download', 1), 53),\n",
       " (('print', 'articl', 4), 53),\n",
       " (('print', 'individu', 6), 53),\n",
       " (('download', 'articl', 3), 53),\n",
       " (('download', 'individu', 5), 53),\n",
       " (('articl', 'individu', 2), 53),\n",
       " (('oilfield', 'commun', 1), 37),\n",
       " (('middl', 'east', 1), 36),\n",
       " (('silver', 'creek', 1), 34),\n",
       " (('rel', 'strength', 1), 31),\n",
       " (('investor', 'daili', 2), 30),\n",
       " (('correspond', 'tabl', 1), 29),\n",
       " (('per', 'cent', 1), 28),\n",
       " (('nobl', 'midstream', 1), 28),\n",
       " (('individu', 'articl', 1), 24),\n",
       " (('individu', 'maintain', 4), 24),\n",
       " (('individu', 'author', 7), 24),\n",
       " (('articl', 'maintain', 3), 24),\n",
       " (('articl', 'author', 6), 24),\n",
       " (('articl', 'certain', 8), 24),\n",
       " (('maintain', 'author', 3), 24),\n",
       " (('maintain', 'certain', 5), 24),\n",
       " (('maintain', 'case', 6), 24),\n",
       " (('maintain', 'content', 7), 24),\n",
       " (('author', 'certain', 2), 24),\n",
       " (('author', 'case', 3), 24),\n",
       " (('author', 'content', 4), 24),\n",
       " (('author', 'copi', 8), 24),\n",
       " (('certain', 'case', 1), 24),\n",
       " (('certain', 'content', 2), 24),\n",
       " (('certain', 'copi', 6), 24),\n",
       " (('case', 'content', 1), 24),\n",
       " (('case', 'copi', 5), 24),\n",
       " (('soda', 'ash', 1), 23),\n",
       " (('salt', 'creek', 1), 22),\n",
       " (('forecast', 'period', 1), 21),\n",
       " (('pin', 'oak', 1), 21),\n",
       " (('exclus', 'ibd', 1), 20),\n",
       " (('exclus', 'analysi', 2), 20),\n",
       " (('exclus', 'action', 4), 20),\n",
       " (('exclus', 'news', 5), 20)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stopword_list = stopwords.words('english')\n",
    "\n",
    "target_word_pair = Counter()\n",
    "for tokens in target_token:\n",
    "    for i in range(len(tokens) - 1):\n",
    "        (w1, w2) = (tokens[i], tokens[i + 1])\n",
    "        if w1 not in stop_word and w2 not in stop_word:\n",
    "            target_word_pair[(w1, w2)] += 1\n",
    "\n",
    "other_word_pair = Counter()\n",
    "for tokens in other_token:\n",
    "    for i in range(len(tokens) - 1):\n",
    "        (w1, w2) = (tokens[i], tokens[i + 1])\n",
    "        if w1 not in stop_word and w2 not in stop_word:\n",
    "            other_word_pair[(w1, w2)] += 1\n",
    "\n",
    "window_size = 9\n",
    "\n",
    "target_pair_counts = Counter()\n",
    "target_pair_distance_counts = Counter()\n",
    "for tokens in target_token:\n",
    "    for i in range(len(tokens) - 1):\n",
    "        for distance in range(1, window_size):\n",
    "            if i + distance < len(tokens):\n",
    "                w1 = tokens[i]\n",
    "                w2 = tokens[i + distance]\n",
    "                if w1 not in stop_word and w2 not in stop_word:\n",
    "                    target_pair_distance_counts[(w1, w2, distance)] += 1\n",
    "                    target_pair_counts[(w1, w2)] += 1\n",
    "\n",
    "other_pair_counts = Counter()\n",
    "other_pair_distance_counts = Counter()\n",
    "for tokens in other_token:\n",
    "    for i in range(len(tokens) - 1):\n",
    "        for distance in range(1, window_size):\n",
    "            if i + distance < len(tokens):\n",
    "                w1 = tokens[i]\n",
    "                w2 = tokens[i + distance]\n",
    "                if w1 not in stop_word and w2 not in stop_word:\n",
    "                    other_pair_distance_counts[(w1, w2, distance)] += 1\n",
    "                    other_pair_counts[(w1, w2)] += 1\n",
    "\n",
    "set(dict(target_pair_distance_counts.most_common(300)).keys()) - set(dict(other_pair_distance_counts.most_common(300)).keys())\n",
    "target_pair_distance_counts.most_common(100)\n",
    "other_pair_distance_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('actual', 'result'),\n",
       " ('al', 'hilal'),\n",
       " ('all', 'statement'),\n",
       " ('ani', 'statement'),\n",
       " ('aramco', 'also'),\n",
       " ('aramco', 'complet'),\n",
       " ('aramco', 'continu'),\n",
       " ('artifici', 'lift'),\n",
       " ('barrel', 'per'),\n",
       " ('base', 'metal'),\n",
       " ('been', 'segment'),\n",
       " ('circular', 'economi'),\n",
       " ('consent', 'decre'),\n",
       " ('cryogen', 'person'),\n",
       " ('downstream', 'network'),\n",
       " ('eagl', 'ford'),\n",
       " ('emerg', 'opportun'),\n",
       " ('epic', 'ngl'),\n",
       " ('exchang', 'commiss'),\n",
       " ('expans', 'project'),\n",
       " ('fastest', 'grow'),\n",
       " ('field', 'trial'),\n",
       " ('focu', 'area'),\n",
       " ('food', 'beverag'),\n",
       " ('futur', 'growth'),\n",
       " ('grand', 'view'),\n",
       " ('gray', 'oak'),\n",
       " ('group', 'provid'),\n",
       " ('growth', 'dure'),\n",
       " ('he', 'said'),\n",
       " ('he', 'say'),\n",
       " ('hilal', 'publish'),\n",
       " ('integr', 'chemic'),\n",
       " ('intern', 'seaway'),\n",
       " ('iron', 'hors'),\n",
       " ('lift', 'system'),\n",
       " ('materi', 'deriv'),\n",
       " ('metal', 'preciou'),\n",
       " ('most', 'import'),\n",
       " ('news', 'sep'),\n",
       " ('open', 'season'),\n",
       " ('partner', 'lp'),\n",
       " ('per', 'day'),\n",
       " ('person', 'care'),\n",
       " ('person', 'protect'),\n",
       " ('phillip', 'partner'),\n",
       " ('pleas', 'visit'),\n",
       " ('polymer', 'surfact'),\n",
       " ('poni', 'express'),\n",
       " ('power', 'gener'),\n",
       " ('preciou', 'metal'),\n",
       " ('press', 'releas'),\n",
       " ('protect', 'equip'),\n",
       " ('r', 'd'),\n",
       " ('resourc', 'base'),\n",
       " ('river', 'gateway'),\n",
       " ('saudi', 'aramco'),\n",
       " ('segment', 'forecast'),\n",
       " ('segment', 'into'),\n",
       " ('short', 'path'),\n",
       " ('straight', 'head'),\n",
       " ('submers', 'pump'),\n",
       " ('such', 'statement'),\n",
       " ('syndig', 'media'),\n",
       " ('umbil', 'riser'),\n",
       " ('under', 'construct'),\n",
       " ('wholli', 'own'),\n",
       " ('璽', '玲')}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dict(target_word_pair.most_common(100)).keys()) - set(dict(other_word_pair.most_common(100)).keys())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
